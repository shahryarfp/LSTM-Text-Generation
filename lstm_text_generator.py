# -*- coding: utf-8 -*-
"""LSTM_Text_Generator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bIaF5OL4lTbgNYAObAIkhbrdTe2CwKzu
"""

from keras.models import Sequential
from keras.layers import Dense, Dropout, LSTM
from tensorflow.keras.optimizers import RMSprop
from keras.callbacks import ModelCheckpoint
from matplotlib import pyplot as plt
import numpy as np
import random
import copy

"""## Loading Text File"""

filename = "/content/dataset.txt"
all_text = open(filename, 'r', encoding='utf-8').read().lower()
print('Num Of Chars:', len(all_text))
print('____________________ \n')
print(all_text[0:150])

"""## Preprocessing"""

#In first step text was converted to a lower case
#removing numbers
all_text = ''.join(c for c in all_text if not c.isdigit())

#removing non alphabetic chars
values = list("abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ ")
values.append('\n')
def remove_non_alpha(my_string = ""):
  for item in my_string:
    if item not in values:
      my_string = my_string.replace(item, "")
  return my_string

all_text = remove_non_alpha(all_text)

chars = sorted(list(set(all_text)))
print('Num of chars in a text:', len(all_text))
print('Num of char types in a text:', len(chars))

#dictionary of chars mapped to int
char_to_int_dict = dict((c, i) for i, c in enumerate(chars))
print('Char to int dict:\n',char_to_int_dict)
#dictionary of int mapped to chars
int_to_char_dict = dict((i, c) for i, c in enumerate(chars))
print('Int to char dict:\n',int_to_char_dict)

"""## Doing the Basics of Algorithm"""

seq_length = 65
jump = 10
sentences = []
next_chars = []
for i in range(0, len(all_text) - seq_length, jump):
  sentences.append(all_text[i: i + seq_length])
  next_chars.append(all_text[i + seq_length])
print('for example:\n\n', sentences[0], '\n\nwe have to predict:', next_chars[0])

x = np.zeros((len(sentences), seq_length, len(chars)), dtype=np.bool)
y = np.zeros((len(sentences), len(chars)), dtype=np.bool)
for i, sentence in enumerate(sentences):
  for t, char in enumerate(sentence):
    x[i, t, char_to_int_dict[char]] = True
  y[i, char_to_int_dict[next_chars[i]]] = True

print('x shape:', x.shape)
print('y shape:', y.shape)
print('x[0]:\n', x[0])
print('y[0]:\n', y[0])

"""## Creating the Model"""

#Two LSTM layer used
model = Sequential()
model.add(LSTM(64, input_shape=(seq_length, len(chars)), return_sequences = True))
model.add(Dropout(0.25))
model.add(LSTM(64))
model.add(Dropout(0.25))
model.add(Dense(len(chars), activation = 'softmax'))

my_optimizer = RMSprop(lr = 0.01)
# my_optimizer = 'adam'
# my_optimizer = 'SGD'

# my_loss = 'categorical_crossentropy'
my_loss = "binary_crossentropy"
# my_loss = "kl_divergence"

model.compile(loss = my_loss, optimizer = my_optimizer, metrics = ['accuracy'])
model.summary()

"""## Fitting the Model"""

history = model.fit(x, y, batch_size = 128, epochs = 60, validation_split = 0.15)

"""## Results"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'])
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'])
plt.show()

"""## Generating Text"""

def find_next_char(preds):
  preds = np.asarray(preds).astype('float64')
  preds_ = np.exp(np.log(preds))
  return int_to_char_dict[np.argmax(np.random.multinomial(1, preds_ / np.sum(preds_), 1))]

start_index = random.randint(0, len(all_text) - 300)
sentence = all_text[start_index: start_index + seq_length]
generated = ''
initial_sentence = copy.deepcopy(sentence)

for i in range(200):
  x_pred = np.zeros((1, seq_length, len(chars)))
  for t, char in enumerate(sentence):
    x_pred[0, t, char_to_int_dict[char]] = True
  preds = model.predict(x_pred)[0]
  next_char = find_next_char(preds)
  generated += next_char
  sentence = sentence[1:] + next_char

print('\nInitial Sentence:\n', initial_sentence,'\n')
print('Generated after initial sentence:\n','...', generated)

